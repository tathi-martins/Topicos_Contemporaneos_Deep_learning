{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ncACgA2yC8K"
      },
      "source": [
        "### **Introdução às LSTMs (Long Short-Term Memory)**\n",
        "\n",
        "As redes LSTM (Long Short-Term Memory) são um tipo especial de RNN projetada para lidar com o problema de dependências de longo prazo em sequências de dados. Elas são amplamente utilizadas em tarefas de processamento de linguagem natural, reconhecimento de fala, e outras aplicações que envolvem sequências.\n",
        "\n",
        "#### **Por que LSTMs?**\n",
        "\n",
        "Em RNNs tradicionais, o problema de desvanecimento de gradientes pode dificultar o aprendizado de dependências de longo prazo. As LSTMs resolvem esse problema através de uma arquitetura de memória mais complexa, que inclui células de memória capazes de preservar informações ao longo de várias etapas de tempo.\n",
        "\n",
        "#### **Arquitetura de uma LSTM**\n",
        "\n",
        "As LSTMs introduzem três \"portas\" (gates) principais para controlar o fluxo de informações:\n",
        "- **Porta de Entrada (Input Gate)**: Controla quanta informação da entrada atual deve ser armazenada na célula de memória.\n",
        "- **Porta de Esquecimento (Forget Gate)**: Decide quanta informação da célula de memória anterior deve ser mantida.\n",
        "- **Porta de Saída (Output Gate)**: Controla quanta informação da célula de memória deve ser utilizada para produzir a saída atual.\n",
        "\n",
        "Matematicamente, a atualização de uma célula LSTM pode ser descrita pelas seguintes equações:\n",
        "\n",
        "$$\n",
        "f_t = \\sigma(W_f \\cdot [h_{t-1}, x_t] + b_f)\n",
        "$$\n",
        "$$\n",
        "i_t = \\sigma(W_i \\cdot [h_{t-1}, x_t] + b_i)\n",
        "$$\n",
        "$$\n",
        "\\tilde{C}_t = \\tanh(W_C \\cdot [h_{t-1}, x_t] + b_C)\n",
        "$$\n",
        "$$\n",
        "C_t = f_t \\cdot C_{t-1} + i_t \\cdot \\tilde{C}_t\n",
        "$$\n",
        "$$\n",
        "o_t = \\sigma(W_o \\cdot [h_{t-1}, x_t] + b_o)\n",
        "$$\n",
        "$$\n",
        "h_t = o_t \\cdot \\tanh(C_t)\n",
        "$$\n",
        "\n",
        "Onde:\n",
        "- $f_t$, $i_t$, $o_t$ são as portas de esquecimento, entrada e saída, respectivamente.\n",
        "- $C_t$ é o estado da célula.\n",
        "- $h_t$ é o estado oculto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "doQsNXuayC8S"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypBqu6aryC8U"
      },
      "source": [
        "### **Primeiros Passos com LSTM - Entradas Aleatórias**\n",
        "\n",
        "Vamos começar criando uma LSTM simples e alimentá-la com entradas aleatórias. Isso nos ajudará a entender como a LSTM processa os dados e o formato das saídas.\n",
        "\n",
        "#### **Explicação do Código**\n",
        "\n",
        "- **`nn.LSTM`**: Implementa uma LSTM básica com uma ou mais camadas.\n",
        "- **Parâmetros principais**:\n",
        "  - `input_size`: Dimensão das entradas em cada passo de tempo.\n",
        "  - `hidden_size`: Número de unidades na célula LSTM.\n",
        "  - `num_layers`: Número de camadas empilhadas de LSTM.\n",
        "  - `batch_first=True`: Faz com que o batch seja a primeira dimensão no tensor de entrada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "myZ4PtpQyC8W"
      },
      "outputs": [],
      "source": [
        "# Configurações\n",
        "input_size = 5  # Tamanho da entrada em cada passo de tempo\n",
        "hidden_size = 10  # Número de unidades na camada oculta\n",
        "num_layers = 2  # Número de camadas empilhadas\n",
        "\n",
        "# Criando uma LSTM\n",
        "lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUOkI5NZyC8Y"
      },
      "outputs": [],
      "source": [
        "# Criando uma entrada aleatória: (batch_size, seq_len, input_size)\n",
        "batch_size = 8\n",
        "seq_len = 7\n",
        "x = torch.randn(batch_size, seq_len, input_size)\n",
        "\n",
        "# Executando a LSTM\n",
        "output, (hn, cn) = lstm(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUIwqyQuyC8a"
      },
      "source": [
        "### **Interpretação das Saídas da LSTM**\n",
        "\n",
        "Vamos analisar o que as diferentes saídas da LSTM significam:\n",
        "\n",
        "- **`output`**: Contém a saída de cada passo de tempo para cada sequência no batch. A forma será `(batch_size, seq_len, hidden_size)`.\n",
        "- **`hn`**: O estado oculto final para cada camada e cada sequência no batch. A forma será `(num_layers, batch_size, hidden_size)`.\n",
        "- **`cn`**: O estado da célula final para cada camada e cada sequência no batch. A forma será a mesma que `hn`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-wiHZ61yC8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c3de8b8-b993-414f-ac03-417a33d70102"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape da saída:  torch.Size([8, 7, 10])\n",
            "Shape do estado oculto hn:  torch.Size([2, 8, 10])\n",
            "Shape do estado da célula cn:  torch.Size([2, 8, 10])\n"
          ]
        }
      ],
      "source": [
        "# Analisando as saídas\n",
        "print(\"Shape da saída: \", output.shape)\n",
        "print(\"Shape do estado oculto hn: \", hn.shape)\n",
        "print(\"Shape do estado da célula cn: \", cn.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JcCxudjuyC8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49ca5398-f2d6-41d0-ee64-9f28ffed0838"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Novo comprimento da sequência: 5\n",
            "Shape da saída:  torch.Size([8, 5, 10])\n",
            "Shape do estado oculto hn:  torch.Size([2, 8, 10])\n",
            "Shape do estado da célula cn:  torch.Size([2, 8, 10])\n",
            "\n",
            "Novo tamanho do batch: 32\n",
            "Shape da saída:  torch.Size([32, 5, 10])\n",
            "Shape do estado oculto hn:  torch.Size([2, 32, 10])\n",
            "Shape do estado da célula cn:  torch.Size([2, 32, 10])\n"
          ]
        }
      ],
      "source": [
        "# Modificando o comprimento da sequência\n",
        "seq_len = 5\n",
        "x = torch.randn(batch_size, seq_len, input_size)\n",
        "output, (hn, cn) = lstm(x)\n",
        "\n",
        "print(\"Novo comprimento da sequência:\", seq_len)\n",
        "print(\"Shape da saída: \", output.shape)\n",
        "print(\"Shape do estado oculto hn: \", hn.shape)\n",
        "print(\"Shape do estado da célula cn: \", cn.shape)\n",
        "\n",
        "# Modificando o tamanho do batch\n",
        "batch_size = 32\n",
        "x = torch.randn(batch_size, seq_len, input_size)\n",
        "output, (hn, cn) = lstm(x)\n",
        "\n",
        "print(\"\\nNovo tamanho do batch:\", batch_size)\n",
        "print(\"Shape da saída: \", output.shape)\n",
        "print(\"Shape do estado oculto hn: \", hn.shape)\n",
        "print(\"Shape do estado da célula cn: \", cn.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yK1GMT6ZyC8d"
      },
      "source": [
        "### **Usando um Estado Inicial de LSTM**\n",
        "\n",
        "Normalmente, as LSTMs começam com um estado oculto e um estado de célula inicializados como zeros. No entanto, podemos fornecer estados iniciais personalizados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LyipfimyC8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10a8c31a-ea62-4571-cc92-f44f2a9fef04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape da saída:  torch.Size([32, 5, 10])\n",
            "Shape do estado oculto hn:  torch.Size([2, 32, 10])\n",
            "Shape do estado da célula cn:  torch.Size([2, 32, 10])\n"
          ]
        }
      ],
      "source": [
        "# Estado inicial personalizado\n",
        "h0 = torch.randn(num_layers, batch_size, hidden_size)\n",
        "c0 = torch.randn(num_layers, batch_size, hidden_size)\n",
        "\n",
        "# Executando a LSTM com estados iniciais personalizados\n",
        "output, (hn, cn) = lstm(x, (h0, c0))\n",
        "\n",
        "print(\"Shape da saída: \", output.shape)\n",
        "print(\"Shape do estado oculto hn: \", hn.shape)\n",
        "print(\"Shape do estado da célula cn: \", cn.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6daR1giyC8f"
      },
      "source": [
        "### **Classificação de Nacionalidade de Nomes com LSTM**\n",
        "\n",
        "Neste exemplo, vamos usar uma LSTM para classificar a nacionalidade de nomes de pessoas. O conjunto de dados contém nomes associados às suas respectivas nacionalidades. A tarefa da LSTM será aprender a classificar corretamente esses nomes em diferentes nacionalidades.\n",
        "\n",
        "#### **Descrição do Problema**\n",
        "\n",
        "Vamos utilizar um conjunto de dados que contém nomes e suas respectivas nacionalidades. A LSTM será treinada para prever a nacionalidade com base no nome dado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMCeTPSlyC8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2f7f5b5-f518-4cee-e5e4-4bb4c541c5aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-19 19:32:06--  https://download.pytorch.org/tutorial/data.zip\n",
            "Resolving download.pytorch.org (download.pytorch.org)... 18.238.238.104, 18.238.238.114, 18.238.238.82, ...\n",
            "Connecting to download.pytorch.org (download.pytorch.org)|18.238.238.104|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2882130 (2.7M) [application/zip]\n",
            "Saving to: ‘data/data.zip’\n",
            "\n",
            "data.zip            100%[===================>]   2.75M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2024-12-19 19:32:06 (42.7 MB/s) - ‘data/data.zip’ saved [2882130/2882130]\n",
            "\n",
            "Archive:  data/data.zip\n",
            "  inflating: ./data/eng-fra.txt      \n",
            "   creating: ./data/names/\n",
            "  inflating: ./data/names/Arabic.txt  \n",
            "  inflating: ./data/names/Chinese.txt  \n",
            "  inflating: ./data/names/Czech.txt  \n",
            "  inflating: ./data/names/Dutch.txt  \n",
            "  inflating: ./data/names/English.txt  \n",
            "  inflating: ./data/names/French.txt  \n",
            "  inflating: ./data/names/German.txt  \n",
            "  inflating: ./data/names/Greek.txt  \n",
            "  inflating: ./data/names/Irish.txt  \n",
            "  inflating: ./data/names/Italian.txt  \n",
            "  inflating: ./data/names/Japanese.txt  \n",
            "  inflating: ./data/names/Korean.txt  \n",
            "  inflating: ./data/names/Polish.txt  \n",
            "  inflating: ./data/names/Portuguese.txt  \n",
            "  inflating: ./data/names/Russian.txt  \n",
            "  inflating: ./data/names/Scottish.txt  \n",
            "  inflating: ./data/names/Spanish.txt  \n",
            "  inflating: ./data/names/Vietnamese.txt  \n"
          ]
        }
      ],
      "source": [
        "# Download do conjunto de dados em data/\n",
        "!wget -P data/ https://download.pytorch.org/tutorial/data.zip\n",
        "\n",
        "# Descompactando o arquivo\n",
        "!unzip data/data.zip -d ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yaFEjQCgyC8g"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import unicodedata\n",
        "import string\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3h7k2UKyC8g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0de07912-8344-4032-8cbf-3dcb53171093"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset size: 20074\n",
            "torch.Size([5, 1, 58]) tensor([0]) Smith Scottish\n"
          ]
        }
      ],
      "source": [
        "class NameDataset(Dataset):\n",
        "    def __init__(self, data_path):\n",
        "        self.all_letters = \"-\" + string.ascii_letters + \" .,;'\"\n",
        "        self.n_letters = len(self.all_letters)\n",
        "        self.NULL_IDX = 0\n",
        "        self.cat2idx, self.idx2cat, self.data = self.load_data(data_path)\n",
        "        self.letter2idx = {letter: idx for idx, letter in enumerate(self.all_letters)}\n",
        "\n",
        "    # Carregar e processar os dados\n",
        "    def load_data(self, path):\n",
        "        cat2idx = {}\n",
        "        idx2cat = {}\n",
        "        data = []\n",
        "        for idx, filename in enumerate(glob.glob(path)):\n",
        "            category = os.path.splitext(os.path.basename(filename))[0]\n",
        "            cat2idx[category] = idx\n",
        "            idx2cat[idx] = category\n",
        "\n",
        "            for line in open(filename, encoding='utf-8').read().strip().split('\\n'):\n",
        "                name = self.unicode_to_ascii(line)\n",
        "                data.append((name, category))\n",
        "        return cat2idx, idx2cat, data\n",
        "\n",
        "    # Função auxiliar para remover acentos\n",
        "    def unicode_to_ascii(self, s):\n",
        "        return ''.join(\n",
        "            c for c in unicodedata.normalize('NFD', s)\n",
        "            if unicodedata.category(c) != 'Mn'\n",
        "        )\n",
        "\n",
        "    # Converter letra para tensor <1 x n_letters>\n",
        "    def letter_to_tensor(self, letter):\n",
        "        tensor = torch.zeros(1, self.n_letters)\n",
        "        tensor[0][self.letter2idx.get(letter, self.NULL_IDX)] = 1\n",
        "        return tensor\n",
        "\n",
        "    # Converter nome para tensor <name_length x 1 x n_letters>\n",
        "    def name_to_tensor(self, name):\n",
        "        tensor = torch.zeros(len(name), 1, self.n_letters)\n",
        "        for li, letter in enumerate(name):\n",
        "            tensor[li][0][self.letter2idx.get(letter, self.NULL_IDX)] = 1\n",
        "        return tensor\n",
        "\n",
        "    def tensor_to_name(self, tensor):\n",
        "        idx = torch.argmax(tensor, dim=-1)\n",
        "        return ''.join(self.all_letters[i] for i in idx)\n",
        "\n",
        "    # Retornar o tamanho do dataset\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    # Recuperar um item do dataset\n",
        "    def __getitem__(self, idx):\n",
        "        name, category = self.data[idx]\n",
        "        name = self.name_to_tensor(name)\n",
        "        category = torch.tensor([self.cat2idx[category]], dtype=torch.long)\n",
        "        return name, category\n",
        "\n",
        "# Exemplo de uso do dataset\n",
        "dataset = NameDataset('data/names/*.txt')\n",
        "\n",
        "# Exibir o tamanho do dataset e um exemplo de tensor\n",
        "print(f\"Dataset size: {len(dataset)}\")\n",
        "name, category = dataset[0]\n",
        "print(name.shape, category, dataset.tensor_to_name(name), dataset.idx2cat[category.item()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNSLPgMayC8h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9764f9d9-9edd-4ced-efef-ce64e92c26f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamanho do dataset de treinamento: 16059\n",
            "Tamanho do dataset de teste: 4015\n"
          ]
        }
      ],
      "source": [
        "# Caminho para os arquivos de dados\n",
        "data_path = 'data/names/*.txt'\n",
        "\n",
        "# Criação do dataset\n",
        "dataset = NameDataset(data_path)\n",
        "\n",
        "# Divisão do dataset em treinamento e teste\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "print(f\"Tamanho do dataset de treinamento: {len(train_dataset)}\")\n",
        "print(f\"Tamanho do dataset de teste: {len(test_dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1C8TSDzyC8h"
      },
      "outputs": [],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "def collate_fn(batch):\n",
        "    names, categories = zip(*batch)\n",
        "\n",
        "    # Padding dos tensores de nomes usando o valor do caractere nulo\n",
        "    names_padded = pad_sequence(names, batch_first=True, padding_value=dataset.NULL_IDX).squeeze()\n",
        "\n",
        "    # Converte lista de categorias para tensor\n",
        "    categories = torch.cat(categories)\n",
        "\n",
        "    return names_padded, categories\n",
        "\n",
        "\n",
        "# Criação dos DataLoaders\n",
        "batch_size = 8\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2wq10zsyC8h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fbf03f1-3805-4d78-90e6-eb89ebb70ec0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 9, 58]) torch.Size([8])\n"
          ]
        }
      ],
      "source": [
        "# Exemplo de uso do DataLoader\n",
        "names, categories = next(iter(test_loader))\n",
        "print(names.shape, categories.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCn8fi_VyC8i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9f4b24c-179c-444a-b3d9-80502b9ce1fe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Derrick--', 'English')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "idx = 2\n",
        "dataset.tensor_to_name(names[idx]), dataset.idx2cat[categories[idx].item()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ugRP_yryC8i"
      },
      "source": [
        "### **Treinamento do Modelo LSTM para Classificação de Nacionalidade**\n",
        "\n",
        "Vamos criar e treinar uma LSTM para classificar os nomes em diferentes nacionalidades.\n",
        "\n",
        "#### **Configuração do Modelo**\n",
        "\n",
        "- **`input_size`**: Número de letras possíveis no nome (dimensão do vetor one-hot para cada letra).\n",
        "- **`hidden_size`**: Número de unidades na camada oculta da LSTM.\n",
        "- **`output_size`**: Número de categorias (nacionalidades).\n",
        "- **`num_layers`**: Número de camadas LSTM empilhadas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RS5C8qOtyC8i"
      },
      "outputs": [],
      "source": [
        "class LSTMClassifier(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
        "        super(LSTMClassifier, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x, h=None):\n",
        "        # x: (batch_size, seq_len, input_size)\n",
        "        batch_size, seq_len, _ = x.size()\n",
        "\n",
        "        # h: (num_layers, batch_size, hidden_size)\n",
        "        if h is None:\n",
        "            h = (torch.zeros(self.lstm.num_layers, batch_size, self.lstm.hidden_size).to(x.device),\n",
        "                 torch.zeros(self.lstm.num_layers, batch_size, self.lstm.hidden_size).to(x.device))\n",
        "\n",
        "        # Processa a sequência com a LSTM\n",
        "        out, (hn, cn) = self.lstm(x, h)\n",
        "\n",
        "        # Apenas a última saída de tempo é usada para classificação\n",
        "        out = out[:, -1, :]\n",
        "\n",
        "        # Calcula a saída\n",
        "        y = self.fc(out)\n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DiZuUCxFyC8j"
      },
      "outputs": [],
      "source": [
        "# Configuração do modelo\n",
        "input_size = dataset.n_letters\n",
        "hidden_size = 128\n",
        "output_size = len(dataset.cat2idx)  # Número de nacionalidades\n",
        "num_layers = 1\n",
        "\n",
        "model = LSTMClassifier(input_size, hidden_size, output_size, num_layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjbosqsDyC8j"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VUy1EAs2yC8j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc56c17a-5b37-4974-8884-1d0a0d082a39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2008/2008 [00:11<00:00, 171.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 1.2154372930526733\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2008/2008 [00:09<00:00, 222.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 2.561119794845581\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2008/2008 [00:08<00:00, 228.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Loss: 0.15610671043395996\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2008/2008 [00:08<00:00, 231.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Loss: 1.3882235288619995\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2008/2008 [00:08<00:00, 241.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4, Loss: 0.03230293467640877\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2008/2008 [00:08<00:00, 238.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, Loss: 2.145270586013794\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2008/2008 [00:08<00:00, 228.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6, Loss: 0.8777637481689453\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2008/2008 [00:08<00:00, 235.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7, Loss: 0.3576925992965698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2008/2008 [00:08<00:00, 248.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8, Loss: 0.7077979445457458\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2008/2008 [00:08<00:00, 229.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9, Loss: 0.3319314420223236\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Treinamento\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for names, categories in tqdm(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(names)\n",
        "        loss = criterion(outputs, categories.squeeze())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if epoch % 1 == 0:\n",
        "        print(f'Epoch {epoch}, Loss: {loss.item()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1DQQAqfyC8k"
      },
      "source": [
        "### **Avaliação do Modelo**\n",
        "\n",
        "Após o treinamento, vamos avaliar o modelo no conjunto de teste para verificar como ele se sai na classificação das nacionalidades."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WUQ6U5fyC8k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34c8d22c-b4d6-49e2-b0ed-b77f23f3af5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia no conjunto de teste: 80.32%\n"
          ]
        }
      ],
      "source": [
        "# Avaliação do modelo\n",
        "model.eval()\n",
        "correct = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for names, categories in test_loader:\n",
        "        outputs = model(names)\n",
        "        predicted = torch.argmax(outputs, dim=1)\n",
        "        correct += (predicted == categories.squeeze()).sum().item()\n",
        "\n",
        "accuracy = correct / len(test_dataset)\n",
        "print(f'Acurácia no conjunto de teste: {accuracy * 100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwvr-MrmyC8k"
      },
      "source": [
        "### **Visualização de Resultados**\n",
        "\n",
        "Finalmente, podemos visualizar algumas das classificações feitas pelo modelo para verificar como ele está tomando as decisões."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZonzNYmhyC8l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd568ff0-f9ec-4f9a-e321-abedb632ea43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nome: Boyle | Nacionalidade Real: English | Predição: English\n",
            "\n",
            "Nome: Beveridge | Nacionalidade Real: English | Predição: English\n",
            "\n",
            "Nome: Jirnov | Nacionalidade Real: Russian | Predição: Russian\n",
            "\n",
            "Nome: Nieddu | Nacionalidade Real: Italian | Predição: English\n",
            "\n",
            "Nome: Close | Nacionalidade Real: Greek | Predição: Greek\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for _ in range(5):\n",
        "    i = np.random.randint(len(test_dataset))\n",
        "    name_tensor, category = test_dataset[i]\n",
        "    name_tensor = name_tensor.squeeze().unsqueeze(0)\n",
        "    name = dataset.tensor_to_name(name_tensor[0])\n",
        "    category = category.item()\n",
        "\n",
        "    output = model(name_tensor)\n",
        "    predicted = output.argmax(-1).item()\n",
        "    print(f\"Nome: {name} | Nacionalidade Real: {dataset.idx2cat[category]} | Predição: {dataset.idx2cat[predicted]}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjmzCCH_yC8l"
      },
      "source": [
        "## Exercícios"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjyXtEZGyC8l"
      },
      "source": [
        "### Exercício 1\n",
        "Aumente o número de camadas para 2 e treine o modelo. O que acontece com os resultados?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuração do modelo\n",
        "input_size = dataset.n_letters\n",
        "hidden_size = 128\n",
        "output_size = len(dataset.cat2idx)  # Número de nacionalidades\n",
        "num_layers = 2 # Duas camadas\n",
        "\n",
        "model_2 = LSTMClassifier(input_size, hidden_size, output_size, num_layers)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "optimizer = optim.Adam(model_2.parameters(), lr=0.001)\n",
        "\n",
        "# Treinamento\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for names, categories in tqdm(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model_2(names)\n",
        "        loss = criterion(outputs, categories.squeeze())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if epoch % 1 == 0:\n",
        "        print(f'Epoch {epoch}, Loss: {loss.item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wQ1JAK7Zt0u",
        "outputId": "f242f168-1403-4169-ff80-9deb8c01168c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2008/2008 [00:14<00:00, 142.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 1.0981522798538208\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2008/2008 [00:13<00:00, 147.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1.5356216430664062\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2008/2008 [00:13<00:00, 147.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Loss: 2.6262004375457764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2008/2008 [00:17<00:00, 114.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Loss: 1.0247411727905273\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2008/2008 [00:13<00:00, 147.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4, Loss: 0.7905097007751465\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2008/2008 [00:13<00:00, 147.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, Loss: 1.4416946172714233\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2008/2008 [00:14<00:00, 142.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6, Loss: 0.40854012966156006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2008/2008 [00:13<00:00, 147.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7, Loss: 0.7283409237861633\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2008/2008 [00:13<00:00, 146.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8, Loss: 0.0001937262568389997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2008/2008 [00:14<00:00, 137.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9, Loss: 0.004129721783101559\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Avaliação do modelo\n",
        "model.eval()\n",
        "correct = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for names, categories in test_loader:\n",
        "        outputs = model_2(names)\n",
        "        predicted = torch.argmax(outputs, dim=1)\n",
        "        correct += (predicted == categories.squeeze()).sum().item()\n",
        "\n",
        "accuracy = correct / len(test_dataset)\n",
        "print(f'Acurácia no conjunto de teste: {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeEVMEL6Z5tx",
        "outputId": "947d4c4d-da30-497a-d15d-f90eee2a292a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia no conjunto de teste: 82.42%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A acurácia do modelo subiu de 80.32% para 82.42%. Uma melhora muito tímida, mas demonstra o potencial de aumentar o desempenho se acrescentarmos mais camadas."
      ],
      "metadata": {
        "id": "PEjKtbJTsZVO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESby0iUwyC8l"
      },
      "source": [
        "### Exercício 2\n",
        "Utilize o modelo treinado para fazer a predição da nacionalidade do seu nome"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sobrenome = 'Martins'\n",
        "name_tensor = dataset.name_to_tensor(sobrenome) # Converte string 'Martins' para tensor\n",
        "#output = model_2(name_tensor.unsqueeze(0))\n",
        "predicted_category = output.argmax(-1).item() # Pega o índice da categoria predita\n",
        "predicted_nationality = dataset.idx2cat[predicted_category]  # Pega a string da nacionalidade\n",
        "\n",
        "print(f\"Nome: {sobrenome} | Predição: {predicted_nationality}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDTj7bN4b-pA",
        "outputId": "f4a1155d-55b9-4dbb-8675-879a9ee05a09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nome: Martins | Predição: Greek\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_nationality(sobrenome, model):\n",
        "    name_tensor = dataset.name_to_tensor(sobrenome)\n",
        "    predicted_category = output.argmax(-1).item() # Pega o índice da categoria predita\n",
        "    predicted_nationality = dataset.idx2cat[predicted_category]  # Pega a string da nacionalidade\n",
        "\n",
        "    return f\"Nome: {sobrenome} | Predição: {predicted_nationality}\""
      ],
      "metadata": {
        "id": "5eXz4d7zejs7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_nationality('Souza', model_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "jCo59y_qfDHT",
        "outputId": "7af62338-dd4a-4611-da05-9c955ea3c2bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Nome: Souza | Predição: Greek'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pega o sobrenome, nacionalidade real e a predita**"
      ],
      "metadata": {
        "id": "285MgCLZj8RN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_nationality(name_input):\n",
        "    # Converte o nome fornecido em tensor\n",
        "    name_tensor = dataset.name_to_tensor(name_input)\n",
        "    name_tensor = name_tensor.squeeze().unsqueeze(0)  # Formata para (1, seq_len, n_letters)\n",
        "\n",
        "    # Encontra o índice correspondente no dataset, se disponível\n",
        "    selected_index = None\n",
        "    for idx in range(len(test_dataset)):\n",
        "        test_name_tensor, category = test_dataset[idx]\n",
        "        if dataset.tensor_to_name(test_name_tensor) == name_input:\n",
        "            selected_index = idx\n",
        "            break\n",
        "\n",
        "    # Se o índice for encontrado, pega a nacionalidade real\n",
        "    if selected_index is not None:\n",
        "        _, category = test_dataset[selected_index]\n",
        "        category = category.item()\n",
        "    else:\n",
        "        category = None  # Caso não encontre, assume que não há nacionalidade real no dataset\n",
        "\n",
        "    # Predição pelo modelo\n",
        "    output = model_2(name_tensor)\n",
        "    predicted = output.argmax(-1).item()\n",
        "\n",
        "    # Exibe os resultados\n",
        "    real_nationality = dataset.idx2cat[category] if category is not None else \"Desconhecida\"\n",
        "    print(f\"Nome: {name_input} | Nacionalidade Real: {real_nationality} | Predição: {dataset.idx2cat[predicted]}\")\n"
      ],
      "metadata": {
        "id": "NsUBIwC8hEMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Uso:\n",
        "predict_nationality('Martins')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e788rtm7iULt",
        "outputId": "3db50259-bed6-47c6-9e9e-c7a747c12330"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nome: Martins | Nacionalidade Real: Desconhecida | Predição: English\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Uso:\n",
        "predict_nationality('Souza')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u60IAVkkidBZ",
        "outputId": "1ab39fe7-0d63-4003-af4e-b8f216577cb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nome: Souza | Nacionalidade Real: Desconhecida | Predição: Spanish\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testando com um sobrenome conhecido\n",
        "\n",
        "predict_nationality('Boyle')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFYCOJvGijTQ",
        "outputId": "ee165326-1dad-419c-adb1-9bc6c04c901d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nome: Boyle | Nacionalidade Real: English | Predição: English\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O modelo não conseguiu identificar nenhum dos meus sobrenomes, embora o nome Souza esteja na lista de sobrenomes portugueses, mas foi classificado como Desconhecido. Vamos verificar o se os sobrenomes estão nos datasets de treino ou teste:"
      ],
      "metadata": {
        "id": "yN2_6QF7koAR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sobrenome = 'Souza'\n",
        "\n",
        "# Verificar no dataset de treino\n",
        "found_in_train = any(dataset.tensor_to_name(train_dataset[i][0]) == sobrenome for i in range(len(train_dataset)))\n",
        "print(f\"Souza está no train_dataset? {found_in_train}\")\n",
        "\n",
        "# Verificar no dataset de teste\n",
        "found_in_test = any(dataset.tensor_to_name(test_dataset[i][0]) == sobrenome for i in range(len(test_dataset)))\n",
        "print(f\"Souza está no test_dataset? {found_in_test}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gf6Hras3pwHL",
        "outputId": "abf04315-f6ff-45a4-951f-d9971198137d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Souza está no train_dataset? True\n",
            "Souza está no test_dataset? False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sobrenome = 'Martins'\n",
        "\n",
        "# Verificar no dataset de treino\n",
        "found_in_train = any(dataset.tensor_to_name(train_dataset[i][0]) == sobrenome for i in range(len(train_dataset)))\n",
        "print(f\"Martins está no train_dataset? {found_in_train}\")\n",
        "\n",
        "# Verificar no dataset de teste\n",
        "found_in_test = any(dataset.tensor_to_name(test_dataset[i][0]) == sobrenome for i in range(len(test_dataset)))\n",
        "print(f\"Martins está no test_dataset? {found_in_test}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bS9xsopVp7_4",
        "outputId": "c2e5787e-8293-4adc-8e0d-95df9681acb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Martins está no train_dataset? True\n",
            "Martins está no test_dataset? False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parece que os sobrenomes estão no dataset de treino, mas não no de teste, talvez essa seja a razão dos sobrenomes Souza e Martins estarem classificados como Desconhecidos, eles não aparecem na lista dos sobrenomes de teste. Porém, o fato destes sobrenomes terem sido classificados errôneamente como de outros países significa que o modelo não consegue classificar de forma eficaz os nomes de origem portuguesa e espanhola."
      ],
      "metadata": {
        "id": "ooXEOaMLqvBi"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}